{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1094d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc77b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ratings data\n",
    "ratings = pd.read_csv(\"ml-100k/u.data\", sep=\"\\t\", names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "\n",
    "# Load movie item data\n",
    "items = pd.read_csv(\n",
    "    \"ml-100k/u.item\",\n",
    "    sep=\"|\",\n",
    "    encoding=\"latin-1\",\n",
    "    names=[\"movie_id\", \"movie_title\", \"release_date\", \"video_release_date\", \"IMDb_URL\"] +\n",
    "          [f\"genre_{i}\" for i in range(19)],\n",
    "    usecols=range(24)\n",
    ")\n",
    "\n",
    "df = pd.merge(ratings, items, left_on=\"item_id\", right_on=\"movie_id\")\n",
    "\n",
    "# Preview the merged dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53368d61",
   "metadata": {},
   "source": [
    "### **1. Non-personalized**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2646d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_non_personalized():\n",
    "    \"\"\"\n",
    "    Returns top 10 non-personalized movie recommendations using IMDb-style weighted rating.\n",
    "    No input parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute rating count and average rating per movie\n",
    "    movie_counts = df.groupby('movie_id')['rating'].count()\n",
    "    movie_means = df.groupby('movie_id')['rating'].mean()\n",
    "\n",
    "    movie_stats = pd.DataFrame({\n",
    "        \"rating_count\": movie_counts,\n",
    "        \"average_rating\": movie_means\n",
    "    })\n",
    "\n",
    "    # Merge with movie titles\n",
    "    movie_stats = movie_stats.merge(items[[\"movie_id\", \"movie_title\"]], on=\"movie_id\")\n",
    "    movie_stats.set_index(\"movie_id\", inplace=True)\n",
    "\n",
    "    # Weighted score formula\n",
    "    C = movie_stats[\"average_rating\"].mean()  # global average\n",
    "    m = 100  # minimum votes threshold\n",
    "    movie_stats[\"weighted_score\"] = (\n",
    "        (movie_stats[\"rating_count\"] / (movie_stats[\"rating_count\"] + m)) * movie_stats[\"average_rating\"]\n",
    "        + (m / (movie_stats[\"rating_count\"] + m)) * C\n",
    "    )\n",
    "\n",
    "    # Return top 10 movies by weighted score\n",
    "    top_movies = movie_stats.sort_values(by=\"weighted_score\", ascending=False).head(10).reset_index()\n",
    "    return top_movies[[\"movie_title\", \"average_rating\", \"rating_count\", \"weighted_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f408d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_non_personalized()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a18de66",
   "metadata": {},
   "source": [
    "### **2. Collaborative Filtering (user-based, item-based)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ab7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user-item matrix (entire dataset for now)\n",
    "user_item_matrix = df.pivot_table(index='user_id', columns='item_id', values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aa6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend_user_based(user_id, num_recommendations=5):\n",
    "    \"\"\"\n",
    "    Recommend movies using User-Based Collaborative Filtering.\n",
    "\n",
    "    Returns a pandas DataFrame with movie_title and estimated score.\n",
    "    \"\"\"\n",
    "    # Fill missing with 0 for similarity calc\n",
    "    user_similarity = cosine_similarity(user_item_matrix.fillna(0))\n",
    "    user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)\n",
    "\n",
    "    # Get most similar users (excluding self)\n",
    "    similar_users = user_similarity_df[user_id].drop(user_id).sort_values(ascending=False)\n",
    "\n",
    "    weighted_ratings = pd.Series(dtype=float)\n",
    "\n",
    "    for other_user, sim in similar_users.items():\n",
    "        other_ratings = user_item_matrix.loc[other_user]\n",
    "        weighted = other_ratings * sim\n",
    "        weighted_ratings = weighted_ratings.add(weighted, fill_value=0)\n",
    "\n",
    "    # Remove movies already rated by user\n",
    "    seen_movies = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id].notna()].index\n",
    "    recommendations = weighted_ratings.drop(index=seen_movies, errors='ignore')\n",
    "\n",
    "    top_n = recommendations.sort_values(ascending=False).head(num_recommendations)\n",
    "    titles = items.set_index(\"movie_id\").loc[top_n.index][\"movie_title\"]\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"movie_title\": titles.values\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ce624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_item_based(user_id, num_recommendations=5):\n",
    "    \"\"\"\n",
    "    Recommend movies using Item-Based Collaborative Filtering.\n",
    "\n",
    "    Returns a pandas DataFrame with movie_title and estimated score.\n",
    "    \"\"\"\n",
    "    # Transpose to get item-user matrix\n",
    "    item_similarity = cosine_similarity(user_item_matrix.T.fillna(0))\n",
    "    item_similarity_df = pd.DataFrame(item_similarity, index=user_item_matrix.columns, columns=user_item_matrix.columns)\n",
    "\n",
    "    user_ratings = user_item_matrix.loc[user_id].dropna()\n",
    "    weighted_scores = pd.Series(dtype=float)\n",
    "\n",
    "    for item_id, rating in user_ratings.items():\n",
    "        sim_scores = item_similarity_df[item_id] * rating\n",
    "        weighted_scores = weighted_scores.add(sim_scores, fill_value=0)\n",
    "\n",
    "    # Remove seen items\n",
    "    weighted_scores = weighted_scores.drop(index=user_ratings.index, errors='ignore')\n",
    "\n",
    "    top_n = weighted_scores.sort_values(ascending=False).head(num_recommendations)\n",
    "    titles = items.set_index(\"movie_id\").loc[top_n.index][\"movie_title\"]\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"movie_title\": titles.values\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaf593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_user_based(user_id=5, num_recommendations=5), recommend_item_based(user_id=5, num_recommendations=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f976422",
   "metadata": {},
   "source": [
    "### **3. Content-based Filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe22a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend_content_based(user_id, num_recommendations=5):\n",
    "    \"\"\"\n",
    "    Recommend movies based on content similarity (genre vector).\n",
    "\n",
    "    Returns a DataFrame with top-N movie titles and similarity scores,\n",
    "    with index starting at 1.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure movie_features is set up\n",
    "    movie_features = items.set_index(\"movie_id\")[[\"movie_title\"] + [f\"genre_{i}\" for i in range(19)]]\n",
    "    movie_features = movie_features.drop_duplicates(subset=\"movie_title\")\n",
    "\n",
    "    # --- Build user profile ---\n",
    "    user_ratings = df[df[\"user_id\"] == user_id][[\"item_id\", \"rating\"]]\n",
    "    rated_movies = pd.merge(user_ratings, movie_features, left_on=\"item_id\", right_index=True)\n",
    "    genre_matrix = rated_movies[[f\"genre_{i}\" for i in range(19)]]\n",
    "    user_profile = genre_matrix.T.dot(rated_movies[\"rating\"])\n",
    "\n",
    "    # --- Score all unseen movies ---\n",
    "    seen_ids = user_ratings[\"item_id\"].tolist()\n",
    "    unseen_movies = movie_features[~movie_features.index.isin(seen_ids)]\n",
    "    unseen_features = unseen_movies[[f\"genre_{i}\" for i in range(19)]]\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity([user_profile], unseen_features)[0]\n",
    "    unseen_movies = unseen_movies.copy()\n",
    "    unseen_movies[\"similarity\"] = similarities\n",
    "\n",
    "    # --- Return top N recommendations ---\n",
    "    top_n = unseen_movies.sort_values(by=\"similarity\", ascending=False).head(num_recommendations)\n",
    "    return pd.DataFrame({\n",
    "        \"movie_title\": top_n[\"movie_title\"].values\n",
    "    }, index=range(1, len(top_n) + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ae784",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_content_based(user_id=5, num_recommendations=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acef8ce0",
   "metadata": {},
   "source": [
    "### **4. Matrix Factorisation (collaborative filtering)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db19213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "def recommend_svd_sklearn(user_id, num_recommendations=5):\n",
    "    \"\"\"\n",
    "    Recommend movies using Matrix Factorization (Truncated SVD).\n",
    "    Applies user mean normalization, proper train/test split,\n",
    "    and returns a top-N DataFrame with index starting at 1.\n",
    "    Also prints RMSE of predicted ratings on test set.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Split data\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 2. Build train matrix (user_id x item_id)\n",
    "    train_matrix = train_df.pivot(index=\"user_id\", columns=\"item_id\", values=\"rating\")\n",
    "\n",
    "    # 3. Normalize: subtract user mean rating\n",
    "    user_means = train_matrix.mean(axis=1)\n",
    "    train_matrix_norm = train_matrix.sub(user_means, axis=0).fillna(0)\n",
    "\n",
    "    # 4. Apply Truncated SVD\n",
    "    svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "    reduced_matrix = svd.fit_transform(train_matrix_norm)\n",
    "    approx_matrix = np.dot(reduced_matrix, svd.components_)\n",
    "\n",
    "    # 5. Denormalize by adding user means back\n",
    "    predicted_ratings = pd.DataFrame(approx_matrix, index=train_matrix.index, columns=train_matrix.columns)\n",
    "    predicted_ratings = predicted_ratings.add(user_means, axis=0)\n",
    "\n",
    "    # 6. Evaluate RMSE on test set\n",
    "    true_ratings = []\n",
    "    pred_ratings = []\n",
    "    for _, row in test_df.iterrows():\n",
    "        u, i, r = row[\"user_id\"], row[\"item_id\"], row[\"rating\"]\n",
    "        if u in predicted_ratings.index and i in predicted_ratings.columns:\n",
    "            true_ratings.append(r)\n",
    "            pred_ratings.append(predicted_ratings.loc[u, i])\n",
    "    rmse = sqrt(mean_squared_error(true_ratings, pred_ratings))\n",
    "    # print(\"📉 RMSE (SVD, normalized):\", round(rmse, 4))\n",
    "\n",
    "    # 7. Generate top-N for the given user\n",
    "    if user_id not in predicted_ratings.index:\n",
    "        return pd.DataFrame({\"movie_title\": [\"User not found\"], \"predicted_rating\": [None]})\n",
    "\n",
    "    user_row = predicted_ratings.loc[user_id]\n",
    "    seen_movies = train_matrix.loc[user_id][train_matrix.loc[user_id].notna()].index\n",
    "    unseen_ratings = user_row.drop(seen_movies, errors='ignore')\n",
    "    top_n = unseen_ratings.sort_values(ascending=False).head(num_recommendations)\n",
    "\n",
    "    movie_titles = items.set_index(\"movie_id\").loc[top_n.index][\"movie_title\"]\n",
    "    return pd.DataFrame({\n",
    "        \"movie_title\": movie_titles.values\n",
    "    }, index=range(1, len(top_n) + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cf75cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_svd_sklearn(user_id=5, num_recommendations=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fff3c06",
   "metadata": {},
   "source": [
    "### **5. Hybrid Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6207e8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assignment.ipynb - Cell 16\n",
    "\n",
    "def recommend_hybrid(user_id, num_recommendations=5, alpha=0.5):\n",
    "    if user_id not in predicted_ratings.index:\n",
    "        print(\"User ID not found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- Collaborative Filtering Predictions ---\n",
    "    cf_scores = predicted_ratings.loc[user_id]\n",
    "\n",
    "    # --- Content-Based Predictions ---\n",
    "    user_profile = build_user_profile(user_id)\n",
    "    genre_matrix = movie_features[[f\"genre_{i}\" for i in range(19)]]\n",
    "    cb_similarities = cosine_similarity([user_profile], genre_matrix)[0]\n",
    "    cb_scores = pd.Series(cb_similarities, index=movie_features.index)\n",
    "\n",
    "    # Get movies user hasn't rated\n",
    "    seen_movies = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id].notna()].index\n",
    "    unseen_movie_ids = [mid for mid in movie_features.index if mid not in seen_movies]\n",
    "\n",
    "    # Combine predictions for unseen movies\n",
    "    hybrid_scores = []\n",
    "    for mid in unseen_movie_ids:\n",
    "        if mid in cf_scores and mid in cb_scores:\n",
    "            hybrid = alpha * cf_scores[mid] + (1 - alpha) * cb_scores[mid]\n",
    "            hybrid_scores.append((mid, hybrid))\n",
    "\n",
    "    # Top N\n",
    "    top_n = sorted(hybrid_scores, key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
    "    top_movies = [(movie_features.loc[mid, \"movie_title\"], score) for mid, score in top_n]\n",
    "\n",
    "    return pd.DataFrame(top_movies, columns=[\"movie_title\", \"hybrid_score\"])\n",
    "\n",
    "# Example\n",
    "recommend_hybrid(user_id=5, num_recommendations=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443a8faf",
   "metadata": {},
   "source": [
    "### **6. Generative AI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc169344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assignment.ipynb - Cell 17\n",
    "\n",
    "# Simulate movie descriptions (in real app, you'd use GPT or API calls)\n",
    "movie_descriptions = items[[\"movie_id\", \"movie_title\"]].copy()\n",
    "movie_descriptions[\"description\"] = \"This is a story about \" + movie_descriptions[\"movie_title\"].str.lower() + \" with drama, action, and emotion.\"\n",
    "\n",
    "movie_descriptions.set_index(\"movie_id\", inplace=True)\n",
    "movie_descriptions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fa43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assignment.ipynb - Cell 18\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load pre-trained model (small and fast)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for all movie descriptions\n",
    "desc_embeddings = model.encode(movie_descriptions[\"description\"].tolist(), show_progress_bar=True)\n",
    "movie_descriptions[\"embedding\"] = list(desc_embeddings)\n",
    "\n",
    "movie_descriptions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2846f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Simulate movie descriptions (or load real ones)\n",
    "movie_descriptions = items[\"movie_title\"].astype(str).tolist()\n",
    "\n",
    "# Encode user query\n",
    "user_query = \"I like psychological thrillers with a twist ending\"\n",
    "user_vector = model.encode(user_query, convert_to_tensor=True)\n",
    "\n",
    "# Encode movie descriptions\n",
    "movie_vectors = model.encode(movie_descriptions, convert_to_tensor=True)\n",
    "\n",
    "# Compute similarity\n",
    "cosine_scores = util.cos_sim(user_vector, movie_vectors)\n",
    "\n",
    "# Top N results\n",
    "top_n = cosine_scores[0].topk(10)\n",
    "\n",
    "# Get titles\n",
    "recommended_titles = [movie_descriptions[idx] for idx in top_n.indices.tolist()]\n",
    "recommended_scores = top_n.values.tolist()\n",
    "\n",
    "# Format nicely\n",
    "import pandas as pd\n",
    "recommend_df = pd.DataFrame({\n",
    "    \"movie_title\": recommended_titles,\n",
    "    \"similarity_score\": recommended_scores\n",
    "}, index=range(1, 11))\n",
    "\n",
    "recommend_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8d42a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_svd_sklearn_fold(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Trains SVD on a specific train_df, evaluates RMSE on test_df.\n",
    "    Returns the RMSE score.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build user-item matrix\n",
    "    train_matrix = train_df.pivot(index=\"user_id\", columns=\"item_id\", values=\"rating\")\n",
    "\n",
    "    # Normalize: subtract user mean\n",
    "    user_means = train_matrix.mean(axis=1).fillna(0)\n",
    "    norm_matrix = train_matrix.sub(user_means, axis=0).fillna(0)\n",
    "\n",
    "    # Train SVD\n",
    "    svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "    reduced = svd.fit_transform(norm_matrix)\n",
    "    reconstructed = np.dot(reduced, svd.components_)\n",
    "\n",
    "    # Denormalize predictions\n",
    "    predicted_ratings = pd.DataFrame(reconstructed, index=train_matrix.index, columns=train_matrix.columns)\n",
    "    predicted_ratings = predicted_ratings.add(user_means, axis=0)\n",
    "\n",
    "    # Evaluate RMSE\n",
    "    true_ratings = []\n",
    "    pred_ratings = []\n",
    "\n",
    "    for _, row in test_df.iterrows():\n",
    "        u, i, r = row[\"user_id\"], row[\"item_id\"], row[\"rating\"]\n",
    "        if u in predicted_ratings.index and i in predicted_ratings.columns:\n",
    "            true_ratings.append(r)\n",
    "            pred_ratings.append(predicted_ratings.loc[u, i])\n",
    "\n",
    "    if true_ratings:\n",
    "        return round(sqrt(mean_squared_error(true_ratings, pred_ratings)), 4)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b513252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_svd_rmse_all_folds():\n",
    "    \"\"\"\n",
    "    Runs recommend_svd_sklearn_fold() on u1–u5 and returns RMSE DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    rmse_scores = []\n",
    "\n",
    "    for fold in range(1, 6):\n",
    "        train_path = f\"ml-100k/u{fold}.base\"\n",
    "        test_path = f\"ml-100k/u{fold}.test\"\n",
    "\n",
    "        train_df = pd.read_csv(train_path, sep=\"\\t\", names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "        test_df = pd.read_csv(test_path, sep=\"\\t\", names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "\n",
    "        rmse = recommend_svd_sklearn_fold(train_df, test_df)\n",
    "        rmse_scores.append(rmse)\n",
    "\n",
    "    return pd.DataFrame({\"Fold\": [f\"u{f}\" for f in range(1, 6)], \"RMSE\": rmse_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3841e80a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_svd_rmse_all_folds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sqrt\n\u001b[1;32m----> 7\u001b[0m \u001b[43mevaluate_svd_rmse_all_folds\u001b[49m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate_svd_rmse_all_folds' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "evaluate_svd_rmse_all_folds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edb2fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend_user_based_fold(train_df, user_id, num_recommendations=10):\n",
    "    \"\"\"\n",
    "    User-based collaborative filtering recommendation using a specific fold's train_df.\n",
    "    Returns a DataFrame of top-N recommended movie_ids and movie_titles.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build user-item matrix\n",
    "    user_item_matrix = train_df.pivot(index=\"user_id\", columns=\"item_id\", values=\"rating\")\n",
    "\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        return pd.DataFrame({\"movie_id\": [], \"movie_title\": []})\n",
    "\n",
    "    # Compute user-user similarity\n",
    "    similarity = cosine_similarity(user_item_matrix.fillna(0))\n",
    "    similarity_df = pd.DataFrame(similarity, index=user_item_matrix.index, columns=user_item_matrix.index)\n",
    "\n",
    "    # Sort similar users (excluding self)\n",
    "    similar_users = similarity_df[user_id].drop(user_id).sort_values(ascending=False)\n",
    "\n",
    "    weighted_scores = pd.Series(dtype=float)\n",
    "\n",
    "    for other_user, sim in similar_users.items():\n",
    "        other_ratings = user_item_matrix.loc[other_user]\n",
    "        weighted_scores = weighted_scores.add(other_ratings * sim, fill_value=0)\n",
    "\n",
    "    # Remove already seen items\n",
    "    seen_items = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id].notna()].index\n",
    "    weighted_scores = weighted_scores.drop(seen_items, errors='ignore')\n",
    "\n",
    "    # Top N unseen\n",
    "    top_n = weighted_scores.sort_values(ascending=False).head(num_recommendations)\n",
    "    top_n_ids = top_n.index.tolist()\n",
    "\n",
    "    # Get movie titles safely\n",
    "    top_n_titles = items.set_index(\"movie_id\").loc[top_n_ids][\"movie_title\"]\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"movie_id\": top_n_ids,\n",
    "        \"movie_title\": top_n_titles.values\n",
    "    }, index=range(1, len(top_n_ids) + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e46ec308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_user_cf_precision_recall_all_folds():\n",
    "    \"\"\"\n",
    "    Evaluates user-based CF on u1-u5 folds.\n",
    "    Returns a DataFrame with Precision@10 and Recall@10 per fold.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for fold in range(1, 6):\n",
    "        train_path = f\"ml-100k/u{fold}.base\"\n",
    "        test_path = f\"ml-100k/u{fold}.test\"\n",
    "\n",
    "        train_df = pd.read_csv(train_path, sep=\"\\t\", names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "        test_df = pd.read_csv(test_path, sep=\"\\t\", names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "\n",
    "        user_ids = test_df[\"user_id\"].unique()\n",
    "        precisions, recalls = [], []\n",
    "\n",
    "        for user_id in user_ids:\n",
    "            relevant_items = test_df[(test_df[\"user_id\"] == user_id) & (test_df[\"rating\"] >= 4)][\"item_id\"].tolist()\n",
    "            if not relevant_items:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                recs = recommend_user_based_fold(train_df, user_id, num_recommendations=10)\n",
    "                recommended_ids = recs[\"movie_id\"].tolist()\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            tp = len([item for item in recommended_ids if item in relevant_items])\n",
    "            precision = tp / 10\n",
    "            recall = tp / len(relevant_items)\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "\n",
    "        if precisions and recalls:\n",
    "            avg_precision = round(np.mean(precisions), 4)\n",
    "            avg_recall = round(np.mean(recalls), 4)\n",
    "        else:\n",
    "            avg_precision = 0.0\n",
    "            avg_recall = 0.0\n",
    "\n",
    "        fold_result = {\n",
    "            \"Fold\": f\"u{fold}\",\n",
    "            \"Precision@10\": avg_precision,\n",
    "            \"Recall@10\": avg_recall\n",
    "        }\n",
    "\n",
    "        print(f\"Fold u{fold}: Precision@10 = {fold_result['Precision@10']}, Recall@10 = {fold_result['Recall@10']}\")\n",
    "        results.append(fold_result)\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7271035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold u1: Precision@10 = 0.0, Recall@10 = 0.0\n"
     ]
    }
   ],
   "source": [
    "evaluate_user_cf_precision_recall_all_folds()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
